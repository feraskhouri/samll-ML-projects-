{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris() \n",
    "X = iris.data \n",
    "y = iris.target \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "# Implement and train a simple neural network \n",
    "neural_network = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000) \n",
    "neural_network.fit(X_train, y_train) \n",
    "# Make predictions on the test set \n",
    "y_pred = neural_network.predict(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.89      0.94         9\n",
      "   virginica       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's accuracy and provide a classification report \n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "report = classification_report(y_test, y_pred, target_names=iris.target_names) \n",
    "print(f\"Accuracy: {accuracy:.2f}\") \n",
    "print(\"Classification Report:\") \n",
    "print(report) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pgmpy\n",
      "  Downloading pgmpy-0.1.26-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (2.2.2)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (3.1.2)\n",
      "Requirement already satisfied: torch in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (2.5.1)\n",
      "Collecting statsmodels (from pgmpy)\n",
      "  Downloading statsmodels-0.14.4-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (4.67.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (1.4.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (3.3.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pgmpy) (2.0.3)\n",
      "Collecting google-generativeai (from pgmpy)\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai->pgmpy)\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai->pgmpy)\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai->pgmpy)\n",
      "  Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai->pgmpy)\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai->pgmpy) (4.25.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai->pgmpy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from google-generativeai->pgmpy) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pandas->pgmpy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pandas->pgmpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pandas->pgmpy) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn->pgmpy) (3.5.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels->pgmpy)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from statsmodels->pgmpy) (24.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from torch->pgmpy) (3.16.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from torch->pgmpy) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from torch->pgmpy) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from torch->pgmpy) (75.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from torch->pgmpy) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->pgmpy) (0.4.6)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai->pgmpy)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core->google-generativeai->pgmpy) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai->pgmpy)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai->pgmpy)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->pgmpy) (1.16.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai->pgmpy)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai->pgmpy)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch->pgmpy) (2.1.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->google-generativeai->pgmpy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from pydantic->google-generativeai->pgmpy) (2.27.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.65.2)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\f1930\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2024.2.2)\n",
      "Collecting protobuf (from google-generativeai->pgmpy)\n",
      "  Using cached protobuf-5.29.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy)\n",
      "  Using cached grpcio-1.68.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Downloading pgmpy-0.1.26-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.8/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "   ---------------------------------------- 0.0/760.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 760.0/760.0 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.4-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.1/9.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.2/9.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.5/9.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.1/9.8 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.9/9.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.6 MB 6.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/12.6 MB 3.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.9/12.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/12.6 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.3/12.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.6/12.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n",
      "Using cached protobuf-5.29.0-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached grpcio-1.68.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: uritemplate, pyasn1, protobuf, patsy, grpcio, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, statsmodels, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, pgmpy\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.4\n",
      "    Uninstalling protobuf-4.25.4:\n",
      "      Successfully uninstalled protobuf-4.25.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.65.2\n",
      "    Uninstalling grpcio-1.65.2:\n",
      "      Successfully uninstalled grpcio-1.65.2\n",
      "Successfully installed google-ai-generativelanguage-0.6.10 google-api-core-2.23.0 google-api-python-client-2.154.0 google-auth-2.36.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 googleapis-common-protos-1.66.0 grpcio-1.68.0 grpcio-status-1.68.0 patsy-1.0.1 pgmpy-0.1.26 proto-plus-1.25.0 protobuf-5.29.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 rsa-4.9 statsmodels-0.14.4 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python312\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.14 requires protobuf<5,>=4.25.3, but you have protobuf 5.29.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f1930\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Discretize the continuous features\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')  # 3 bins, uniformly spaced\n",
    "X_train_discrete = discretizer.fit_transform(X_train)\n",
    "X_test_discrete = discretizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f1930\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\preprocessing\\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Discretize the continuous features\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')  # 3 bins, uniformly spaced\n",
    "X_train_discrete = discretizer.fit_transform(X_train)\n",
    "X_test_discrete = discretizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pgmpy:BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n"
     ]
    }
   ],
   "source": [
    "# Combine X_train and y_train into a single DataFrame for model fitting\n",
    "data_train = pd.DataFrame(\n",
    "    np.column_stack([X_train_discrete, y_train]),\n",
    "    columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Target']\n",
    ")\n",
    "\n",
    "# Define the Bayesian Network structure\n",
    "model = BayesianModel([('Feature1', 'Target'), ('Feature2', 'Target'),\n",
    "                       ('Feature3', 'Target'), ('Feature4', 'Target')])\n",
    "\n",
    "# Fit the model using Maximum Likelihood Estimation\n",
    "model.fit(data_train, estimator=MaximumLikelihoodEstimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4340573b85143f38322c06772fdce8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "data_test = pd.DataFrame(\n",
    "    X_test_discrete,\n",
    "    columns=['Feature1', 'Feature2', 'Feature3', 'Feature4']\n",
    ")\n",
    "y_pred = model.predict(data_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = np.mean(y_pred['Target'].values == y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
